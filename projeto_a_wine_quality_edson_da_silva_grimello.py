# -*- coding: utf-8 -*-
"""Projeto A_Wine Quality_Edson da Silva Grimello.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HBFu0spYOLF3iME0dGwPkiAqoaBzv2B1

# Módulo de estatística 

## Projeto A - Análise do dataset "Wine Quality"

### Instruções

- O projeto deverá ser entregue até dia 22/11 antes do início da aula
- O projeto poderá ser feito em grupo com até 4 integrantes
- Serão 2 projetos A e B porém apenas 1 projeto deverá ser entregue e escolhido pelo grupo

- A entrega deve ser feita em jupyter notebook com os códigos explícitos e comentados. Além disso os conceitos, decisões e conclusões usadas devem estar destacadas no notebook

### Informações sobre o projeto

Dataset (conjunto de dados a ser utilizado) está disponível em:
    https://archive.ics.uci.edu/ml/datasets/Wine+Quality

Data Set Information:

The two datasets are related to red and white variants of the Portuguese "Vinho Verde" wine. For more details, consult: [Web Link] or the reference [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).

These datasets can be viewed as classification or regression tasks. The classes are ordered and not balanced (e.g. there are many more normal wines than excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent or poor wines. Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods.


Attribute Information:

Input variables (based on physicochemical tests): <br>
- 1 - fixed acidity
- 2 - volatile acidity
- 3 - citric acid
- 4 - residual sugar
- 5 - chlorides
- 6 - free sulfur dioxide
- 7 - total sulfur dioxide
- 8 - density
- 9 - pH
- 10 - sulphates
- 11 - alcohol

Output variable (based on sensory data): <br>
- 12 - quality (score between 0 and 10)

![image.png](attachment:image.png)

### Etapa 1

**EDA - Análise exploratória de dados**

- Análise das medidas de medidas de posição, dispersão, correlação (análises univaridas e bivariadas) - histograma, boxplot, mapa de calor, etc...
- Exclusão de outliers, caso necessário (sempre explicando a opção)



### Etapa 2

**Regressão Linear**

- Faça um algoritmo que estime a variável “Quality” em função das características físico-químicas dos vinhos
- Colocar comentários sobre a técnica utilizada e análise sobre as variáveis utilizadas, além dos seus respectivos “achados”. Faça uma interpretação do resultado

### Etapa 3

**Regressão logística**

- Sabendo que os vinhos com notas >= 6 são considerados vinhos de boa qualidade faça um algoritmo que classifique os vinhos em “Bom” ou “Ruim” em função de suas características físico-químicas;
- Colocar comentários sobre a técnica utilizada e análise sobre as variáveis utilizadas, além dos seus respectivos “achados”. Faça uma interpretação do resultado

### Etapa 1: EDA
"""

#Importação das bibliotecas que serão utilizadas

import pandas as pd
import numpy as np
from random import sample
import matplotlib.pyplot as plt
import seaborn as sns
import scipy as sp
import plotly.express as px
from scipy.stats import zscore
from sklearn.utils import resample
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import confusion_matrix
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
!pip install --user yellowbrick
import warnings
warnings.filterwarnings('ignore')

!pip install --user yellowbrick

#Importação dos datasets  e visualização das linhas e colunas
url_branco = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'
vinho_branco = pd.read_csv(url_branco, sep= ';')

vinho_branco.head(10)

url_tinto = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'
vinho_tinto = pd.read_csv(url_tinto, sep=';')
vinho_tinto.head(10)

#Verificando quantidade de linhas e colunas dos datasets
vinho_branco.shape

vinho_tinto.shape

#Verificando os typos de dados
vinho_branco.dtypes

vinho_tinto.dtypes

#Visualização das medidas de posição dos datasets
vinho_branco.describe()

vinho_tinto.describe()

#Limpeza de dados: verificação se há dados ausentes ou duplicados
vinho_branco.isnull().sum()

vinho_tinto.isnull().sum()

vinho_branco.duplicated().sum()

vinho_tinto.duplicated().sum()

vinho_branco[vinho_branco.duplicated()]

vinho_tinto[vinho_tinto.duplicated()]

"""OS itens considerados 'duplicados' tratam-se de vinhos com os mesmos valores de variáveis e entendo que não necessariamente são duplicados, mas serão dropados justamente pela duplicação de valores que nao serão de valia para o treinamento do modelo."""

vinho_branco.drop_duplicates(inplace=True)
vinho_branco.shape

vinho_tinto.drop_duplicates(inplace=True)
vinho_tinto.shape

"""Como os datasets são de tamanhos diferentes, sendo o de vinho branco maior,  serão igualados os números das amostras entre brancos e tintos."""

#amostragem simples do branco para igualar número de amostras com o tinto.
amostra_branco = vinho_branco.sample(n=1359,random_state=42)
amostra_branco

#Renomeação do index para identificação dos vinhos tintos e brancos
amostra_branco.index = [f'Vinho_Branco_{i}' for i in range(0,1359)]
amostra_branco

vinho_tinto.index = [f'Vinho_Tinto_{i}' for i in range(0,1359)]
vinho_tinto

#Juntando os dataframes
vinhos = pd.concat([amostra_branco, vinho_tinto])
vinhos

vinhos.info()

"""Removendo Outliers"""

sex_q1 = covid['sex'].quantile(0.25)
sex_q3 = covid['sex'].quantile(0.75)
iqr = sex_q3 - sex_q1
lim_inf = sex_q1 - 1.5*iqr
lim_sup = sex_q3 + 1.5*iqr
print('Outliers:')
print('Q1: ', sex_q1)
print('Q3: ', sex_q3)
print('IQR:              ', iqr)
print('Limite Inferior:  ', lim_inf)
print('Limite Superior:  ', lim_sup)

# = vinhos[vinhos['fixed acidity'] < lim_sup]

for column in vinhos_limpo.columns:
    if column != 'fixed acidity' and column != 'alcohol' and column != 'quality':
        q1 = vinhos_limpo[column].quantile(0.25)
        q3 = vinhos_limpo[column].quantile(0.75)
        iqr = q3 - q1
        lim_inf = q1 - 1.5*iqr
        lim_sup = q3 + 1.5*iqr

        vinhos_limpo = vinhos_limpo[vinhos_limpo[column] < lim_sup]

vinhos_limpo.info()

sns.pairplot(vinhos_limpo, hue='quality')
plt.show()

vinhos_limpo.corr()['quality']

vinhos_limpo.quality.max()

vinhos_limpo.quality.min()

vinhos_limpo.describe().loc['std',:]

vinhos_limpo['quality'].value_counts()

vinhos_limpo['quality'].describe()

#Verificando os tipos de variáveis do dataset para levantar necessidade de conversão
vinhos_limpo.dtypes

"""## Correlações e gráficos"""

#Correlação entre as variáveis e a target 'quality'
for x in vinhos_limpo.columns:
    print(vinhos_limpo[[x,'quality']].corr())
    print()

# Verificação da correlação entre variáveis para visualização no mapa de calor de possíveis pares com informação similar
plt.figure(figsize=(10,10))
sns.heatmap(vinhos_limpo.corr(), color='k', annot=True)
plt.show()

sns.countplot(x='quality', data=vinhos_limpo)

vinhos1 = vinhos_limpo.select_dtypes([np.int, np.float])
for i, col in enumerate(vinhos1.columns):
  plt.figure(i)
  sns.barplot(x='quality', y=col, data=vinhos1)
vinhos1

"""Pelos gráficos percebe-se que o incremento da qualidade está relacionada a baixa 'volatility acidity' e 'chlorides' e a qualidade aparentemente aumenta com valores maiores de 'sulphates', 'citric acid' e 'alcohol'.

"""

#visualizando melhor a relação positiva entre qualidade e alcool
plt.figure(figsize=(15,5))
sns.boxplot(x='quality', y='alcohol', data=vinhos_limpo)
plt.show()

#visualizando melhor a relação positiva entre qualidade e acidos citricos
plt.figure(figsize=(15,5))
sns.boxplot(x='quality', y='citric acid', data=vinhos_limpo)
plt.show()

#visualizando melhor a relação positiva entre qualidade e sulfatos
plt.figure(figsize=(15,5))
sns.boxplot(x='quality', y='sulphates', data=vinhos_limpo)
plt.show()

sns.lmplot(x='alcohol', y='quality', data=vinhos_limpo)

sns.lmplot(x='sulphates', y='quality', data=vinhos_limpo)

sns.lmplot(x='citric acid', y='quality', data=vinhos_limpo)

vinhos_limpo.info()

plt.figure(figsize=(12,8))
sns.distplot(vinhos_limpo['quality'], kde=True)
plt.show()

sns.scatterplot(data=vinhos_limpo, x='density', y='alcohol', hue='quality')
plt.show()

""" ### Etapa 2: Regressão Linear - target (y) = quality"""

X = vinhos_limpo.drop(['quality'], axis = 1)
y = vinhos_limpo['quality']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)
X_train.shape, X_test.shape, y_train.shape, y_test.shape

from sklearn.preprocessing import StandardScaler

std = StandardScaler()

X_train_std = std.fit_transform(X_train)

X_train_std

X_test_std = std.transform(X_test)

X_test_std

from sklearn.linear_model import LinearRegression

linreg = LinearRegression()

linreg.fit(X_train_std, y_train)

y_pred = linreg.predict(X_test_std)
y_pred

fig = plt.figure(figsize=(8,8))
l = plt.plot(y_pred, y_test, 'bo')
plt.setp(l, markersize=10)
plt.setp(l, markerfacecolor='C0')
plt.title('Predito x Valor Real', fontsize=12)
plt.ylabel("Valor Real", fontsize=12)
plt.xlabel("Valor Predito", fontsize=12)

# mostra os valores preditos e originais
xl = np.arange(min(y_test), 1.2*max(y_test),(max(y_test)-min(y_test))/10)
yl = xl
plt.plot(xl, yl, 'r--')

plt.show()

print('Métricas para a Previsão')
print('Erro Absoluto Médio:', np.round(mean_absolute_error(y_test, y_pred), 3))
print('Erro Quadrático Médio:', np.round(mean_squared_error(y_test, y_pred), 3))
print('R^2:', np.round(r2_score(y_test, y_pred), 3))

from sklearn.metrics import r2_score
R2 = r2_score(y_test, y_pred)
print('R2:', R2)

"""### Conclusão do Modelo de Regressão Linear

O modelo de Regressão Linear utilizado se mostrou inadequado para os tipos de dados disponíveis e o R2 baixo demonstra underfit apesar das tratativas dadas aos dados disponíveis.

### Análise dos resíduos
"""

residuos = y_test - y_pred
residuos

plt.scatter(residuos, y_pred)
plt.show()

#Visualizando a distribuição dos residuos
sns.distplot(residuos, kde=True)

from yellowbrick.regressor import ResidualsPlot

visualizador = ResidualsPlot(linreg)
visualizador.fit(X_train_std, y_train)
visualizador.score(X_test_std, y_test)
visualizador.show()
plt.show()

"""### Etapa 3: Regressão Logística"""

# 0 = 'ruim
# 1 = 'bom'
vinhos_limpo['rating'] = np.where(
    vinhos_limpo['quality'].isin(range(1,6)),
    0, 
    1 )

vinhos_limpo['rating'].value_counts(normalize=True)

sns.pairplot(vinhos_limpo, hue="rating")
plt.show()

vinhos_limpo.info()

X = vinhos_limpo[['alcohol','sulphates','density','volatile acidity','citric acid','chlorides']]
y = vinhos_limpo['rating']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)

std = StandardScaler()
X_train_std = std.fit_transform(X_train)
X_test_std = std.transform(X_test)

modelo = LogisticRegression()
modelo.fit(X_train_std, y_train)
y_pred = modelo.predict(X_test_std)

# Matriz de confusão
conf = confusion_matrix(y_test, y_pred)
plot_confusion_matrix(conf_mat=conf)
plt.show()

from sklearn.metrics import accuracy_score
print('Accuracy:', accuracy_score(y_test, y_pred))

from sklearn.metrics import precision_score
print('Precision score:', precision_score(y_test, y_pred))

from sklearn.metrics import recall_score
print('Recall score:', recall_score(y_test, y_pred))

from sklearn.metrics import f1_score
print('F1 Score:', f1_score(y_test, y_pred))

print('\n')
from sklearn.metrics import classification_report

# Classification report
print(classification_report(y_test, y_pred))

"""### Conclusão do Modelo de Regressão Logística

O Modelo de Regressão Logística se mostra eficaz no objetivo de classificação dos vinhos entre bons ou ruins.

### Conclusão Geral

Na EDA, o tratamento dos dados e os métodos utilizados para trabalhar os outliers foram adequados para a montagem dos modelos e os modelos solicitados se mostram adequados para a estimação da variável 'quality' em função das características fisico-quimicas (Reressão Linear) e na classificação dos vinhos em 'Bom' e 'Ruim' também de acordo com as características fisico-quimicas.
"""

